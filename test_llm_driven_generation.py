#!/usr/bin/env python3
"""
Only-Test LLMé©±åŠ¨æµ‹è¯•ç”¨ä¾‹è‡ªåŠ¨ç”ŸæˆéªŒè¯
=========================================

éªŒè¯å®Œæ•´çš„LLMé©±åŠ¨å·¥ä½œæµç¨‹ï¼š
1. ç”¨æˆ·æå‡ºæµ‹è¯•éœ€æ±‚
2. LLMåˆ†æå±å¹•çŠ¶æ€å’Œåº”ç”¨ç‰¹æ€§
3. LLMè‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æµ‹è¯•ç”¨ä¾‹
4. ç³»ç»Ÿæ‰§è¡Œç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹

è¿™æ˜¯Only-Testæ¡†æ¶çš„æ ¸å¿ƒä»·å€¼ï¼šWrite Once, Test Everywhereï¼
"""

import asyncio
import json
import os
import sys
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/mnt/c/Download/git/uni/airtest')
sys.path.insert(0, '/mnt/c/Download/git/uni')

from airtest.lib.visual_recognition.omniparser_client import OmniparserClient
from airtest.lib.mcp_interface.mcp_server import MCPServer, MCPTool, MCPResponse

# æ¨¡æ‹ŸçœŸå®çš„LLMå“åº”ï¼ˆåŸºäºGPT-4æˆ–Claudeçš„å…¸å‹è¾“å‡ºï¼‰
class IntelligentLLMSimulator:
    """
    æ™ºèƒ½LLMæ¨¡æ‹Ÿå™¨
    
    æ¨¡æ‹ŸçœŸå®LLMçš„åˆ†æå’Œç”Ÿæˆèƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š
    - å±å¹•å†…å®¹ç†è§£
    - æµ‹è¯•ç­–ç•¥åˆ¶å®š
    - ç»“æ„åŒ–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
    - è¾¹ç•Œæƒ…å†µè€ƒè™‘
    """
    
    def __init__(self):
        self.conversation_history = []
        self.app_knowledge_base = {
            "com.mobile.brasiltvmobile": {
                "type": "streaming_video_app",
                "key_features": ["video_playback", "quality_settings", "subtitles", "casting"],
                "common_ui_patterns": ["player_controls", "settings_menu", "content_library"],
                "test_priorities": ["playback_stability", "ui_responsiveness", "feature_accessibility"]
            }
        }
    
    async def analyze_user_request(self, user_request: str, screen_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·æµ‹è¯•éœ€æ±‚
        
        Args:
            user_request: ç”¨æˆ·çš„æµ‹è¯•éœ€æ±‚æè¿°
            screen_context: å½“å‰å±å¹•çŠ¶æ€ä¿¡æ¯
            
        Returns:
            åˆ†æç»“æœåŒ…å«æµ‹è¯•ç­–ç•¥å’Œé‡ç‚¹
        """
        logger.info(f"LLMåˆ†æç”¨æˆ·éœ€æ±‚: {user_request}")
        
        # æ¨¡æ‹ŸLLMçš„æ€ç»´è¿‡ç¨‹
        analysis = {
            "request_understanding": {
                "primary_intent": "functional_testing",
                "target_app": "com.mobile.brasiltvmobile", 
                "test_scope": "video_playback_features",
                "complexity_level": "comprehensive"
            },
            "screen_analysis": {
                "current_state": screen_context.get("app_state", "unknown") if screen_context else "video_playing",
                "available_elements": screen_context.get("elements_count", 22) if screen_context else 22,
                "interactive_elements": screen_context.get("interactive_elements", 13) if screen_context else 13,
                "content_identified": "Ironheart S1 Episode 1"
            },
            "test_strategy": {
                "approach": "user_journey_based",
                "priority_scenarios": [
                    "core_playback_functions",
                    "quality_and_settings", 
                    "user_interface_response",
                    "edge_cases_handling"
                ],
                "test_depth": "functional_and_ui_validation"
            },
            "risk_assessment": {
                "critical_paths": ["play_pause", "seek_controls", "settings_access"],
                "potential_issues": ["ui_lag", "setting_persistence", "playback_interruption"],
                "test_priority": "high"
            }
        }
        
        self.conversation_history.append({
            "role": "user",
            "content": user_request,
            "timestamp": datetime.now().isoformat()
        })
        
        self.conversation_history.append({
            "role": "assistant", 
            "content": "analysis_complete",
            "analysis": analysis,
            "timestamp": datetime.now().isoformat()
        })
        
        return analysis
    
    async def generate_test_case(self, analysis_result: Dict[str, Any], omniparser_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åŸºäºåˆ†æç»“æœç”Ÿæˆç»“æ„åŒ–æµ‹è¯•ç”¨ä¾‹
        
        Args:
            analysis_result: éœ€æ±‚åˆ†æç»“æœ
            omniparser_data: Omniparseræä¾›çš„å…ƒç´ æ•°æ®
            
        Returns:
            å®Œæ•´çš„JSONæµ‹è¯•ç”¨ä¾‹å®šä¹‰
        """
        logger.info("LLMå¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        
        # æ¨¡æ‹ŸLLMçš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæ€è€ƒè¿‡ç¨‹
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
        
        # åŸºäºå®é™…omniparseræ•°æ®çš„æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
        test_case = {
            "metadata": {
                "testcase_id": f"TC_LLM_GENERATED_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "name": "BrasilTVMobileæ™ºèƒ½æ’­æ”¾åŠŸèƒ½æµ‹è¯•å¥—ä»¶",
                "description": "ç”±LLMåˆ†æç”¨æˆ·éœ€æ±‚åè‡ªåŠ¨ç”Ÿæˆçš„ç»¼åˆæ’­æ”¾åŠŸèƒ½æµ‹è¯•",
                "generated_by": "Only-Test LLM Engine",
                "generation_timestamp": datetime.now().isoformat(),
                "target_app": "com.mobile.brasiltvmobile",
                "confidence_score": 0.95,
                "estimated_execution_time": "6-10 minutes"
            },
            
            "test_requirements": {
                "user_story": "ä½œä¸ºBrasilTVMobileç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½æµç•…åœ°è§‚çœ‹è§†é¢‘å†…å®¹ï¼ŒåŒ…æ‹¬åŸºæœ¬æ’­æ”¾æ§åˆ¶ã€ç”»è´¨è°ƒæ•´ã€å­—å¹•è®¾ç½®ç­‰åŠŸèƒ½",
                "acceptance_criteria": [
                    "è§†é¢‘èƒ½æ­£å¸¸æ’­æ”¾å’Œæš‚åœ",
                    "è¿›åº¦æ§åˆ¶(å¿«è¿›/å¿«é€€)åŠŸèƒ½æ­£å¸¸",
                    "è®¾ç½®èœå•(ç”»è´¨/å­—å¹•)å¯æ­£å¸¸è®¿é—®",
                    "å…¨å±æ’­æ”¾æ¨¡å¼ç¨³å®šå·¥ä½œ",
                    "UIå“åº”åŠæ—¶ï¼Œæ— æ˜æ˜¾å¡é¡¿"
                ],
                "test_data": {
                    "content": "Ironheart S1 Episode 1",
                    "duration": "40:58",
                    "current_quality": "480P"
                }
            },
            
            "intelligent_scenarios": [
                {
                    "scenario_id": "SMART_PLAYBACK_CONTROL",
                    "name": "æ™ºèƒ½æ’­æ”¾æ§åˆ¶éªŒè¯",
                    "llm_reasoning": "åŸºäºå±å¹•åˆ†æï¼Œæ£€æµ‹åˆ°æ’­æ”¾æ§åˆ¶æŒ‰é’®(UUID: 8fe45ee4)ï¼Œè¿™æ˜¯æœ€æ ¸å¿ƒçš„åŠŸèƒ½ï¼Œå¿…é¡»ä¼˜å…ˆéªŒè¯",
                    "adaptive_steps": [
                        {
                            "step": 1,
                            "action": "llm_analyze_current_state",
                            "description": "LLMåˆ†æå½“å‰æ’­æ”¾çŠ¶æ€",
                            "llm_prompt": "åˆ†æå½“å‰è§†é¢‘æ’­æ”¾ç•Œé¢ï¼Œç¡®å®šæ’­æ”¾çŠ¶æ€ã€è¿›åº¦ä¿¡æ¯å’Œå¯ç”¨æ§åˆ¶é€‰é¡¹"
                        },
                        {
                            "step": 2, 
                            "action": "intelligent_element_interaction",
                            "description": "æ™ºèƒ½ç‚¹å‡»æ’­æ”¾/æš‚åœæŒ‰é’®",
                            "target_element": {
                                "uuid": "8fe45ee4",
                                "type": "playback_control",
                                "llm_identified": True,
                                "confidence": 0.98
                            },
                            "adaptive_logic": {
                                "if_playing": "æ‰§è¡Œæš‚åœæ“ä½œ",
                                "if_paused": "æ‰§è¡Œæ’­æ”¾æ“ä½œ",
                                "verification": "é€šè¿‡è§†è§‰å·®å¼‚æ£€æµ‹ç¡®è®¤çŠ¶æ€å˜åŒ–"
                            }
                        },
                        {
                            "step": 3,
                            "action": "llm_verify_state_change", 
                            "description": "LLMéªŒè¯æ’­æ”¾çŠ¶æ€å˜åŒ–",
                            "verification_strategy": "visual_analysis",
                            "success_criteria": "æ’­æ”¾çŠ¶æ€æˆåŠŸåˆ‡æ¢ï¼ŒUIæ˜¾ç¤ºç›¸åº”å˜åŒ–"
                        }
                    ]
                },
                
                {
                    "scenario_id": "SMART_SEEK_OPERATIONS",
                    "name": "æ™ºèƒ½è¿›åº¦æ§åˆ¶æµ‹è¯•",
                    "llm_reasoning": "æ£€æµ‹åˆ°å¿«è¿›(ae815134)å’Œå¿«é€€(ee9f61ce)æŒ‰é’®ï¼Œéœ€è¦éªŒè¯æ—¶é—´æ§åˆ¶çš„å‡†ç¡®æ€§",
                    "adaptive_steps": [
                        {
                            "step": 4,
                            "action": "capture_initial_time",
                            "description": "è®°å½•å½“å‰æ’­æ”¾æ—¶é—´",
                            "target_element": {
                                "uuid": "dac2a610",
                                "type": "time_display",
                                "expected_format": "MM:SS"
                            }
                        },
                        {
                            "step": 5,
                            "action": "intelligent_seek_backward",
                            "description": "æ™ºèƒ½æ‰§è¡Œå¿«é€€æ“ä½œ",
                            "target_element": {
                                "uuid": "ee9f61ce",
                                "action": "10_second_rewind",
                                "bbox": [0.378, 0.854, 0.429, 0.957]
                            },
                            "llm_validation": {
                                "time_change_expected": "-10 seconds",
                                "tolerance": "Â±2 seconds",
                                "verification_method": "time_comparison"
                            }
                        },
                        {
                            "step": 6,
                            "action": "intelligent_seek_forward",
                            "description": "æ™ºèƒ½æ‰§è¡Œå¿«è¿›æ“ä½œ",
                            "target_element": {
                                "uuid": "ae815134", 
                                "action": "10_second_forward",
                                "bbox": [0.600, 0.857, 0.652, 0.949]
                            }
                        }
                    ]
                },
                
                {
                    "scenario_id": "SMART_SETTINGS_EXPLORATION",
                    "name": "æ™ºèƒ½è®¾ç½®èœå•æµ‹è¯•",
                    "llm_reasoning": "è¯†åˆ«åˆ°ç”»è´¨è®¾ç½®(4a3c8eab)å’Œå­—å¹•æ§åˆ¶(3c5e0a8e)ï¼Œéœ€è¦éªŒè¯è®¾ç½®åŠŸèƒ½çš„å¯è®¿é—®æ€§",
                    "adaptive_steps": [
                        {
                            "step": 7,
                            "action": "explore_quality_settings",
                            "description": "æ¢ç´¢ç”»è´¨è®¾ç½®åŠŸèƒ½", 
                            "target_element": {
                                "uuid": "4a3c8eab",
                                "current_value": "480P",
                                "type": "quality_selector"
                            },
                            "llm_behavior": {
                                "interaction": "tap_to_open_menu",
                                "expectation": "display_quality_options",
                                "adaptive_validation": "check_menu_appearance"
                            }
                        },
                        {
                            "step": 8,
                            "action": "test_subtitle_controls",
                            "description": "æµ‹è¯•å­—å¹•è®¾ç½®åŠŸèƒ½",
                            "target_element": {
                                "uuid": "3c5e0a8e",
                                "content": "Subtitle",
                                "bbox": [0.850, 0.880, 0.884, 0.938]
                            }
                        }
                    ]
                },
                
                {
                    "scenario_id": "SMART_FULLSCREEN_VALIDATION", 
                    "name": "æ™ºèƒ½å…¨å±æ¨¡å¼éªŒè¯",
                    "llm_reasoning": "å½“å‰ä¼¼ä¹å¤„äºå…¨å±æ’­æ”¾çŠ¶æ€ï¼Œéœ€è¦éªŒè¯å…¨å±åŠŸèƒ½å’Œç›¸å…³ç‰¹æ€§ï¼ˆå¦‚æŠ•å±ï¼‰",
                    "adaptive_steps": [
                        {
                            "step": 9,
                            "action": "verify_fullscreen_state",
                            "description": "LLMéªŒè¯å½“å‰å…¨å±çŠ¶æ€",
                            "llm_analysis": {
                                "screen_coverage_check": "videoå å±å¹•æ¯”ä¾‹ > 80%",
                                "ui_minimization_check": "æ§åˆ¶å…ƒç´ å¤„äºoverlayæ¨¡å¼",
                                "fullscreen_indicators": "æ£€æŸ¥å…¨å±ç›¸å…³UIæç¤º"
                            }
                        },
                        {
                            "step": 10,
                            "action": "test_cast_functionality",
                            "description": "æµ‹è¯•æŠ•å±åŠŸèƒ½å¯ç”¨æ€§",
                            "target_element": {
                                "uuid": "d51e702a", 
                                "content": "Cast",
                                "type": "cast_button",
                                "bbox": [0.757, 0.075, 0.806, 0.163]
                            },
                            "expected_behavior": "æ˜¾ç¤ºæŠ•å±è®¾å¤‡åˆ—è¡¨æˆ–æŠ•å±é€‰é¡¹"
                        }
                    ]
                }
            ],
            
            "llm_execution_config": {
                "adaptive_timeout": {
                    "base_timeout": 30,
                    "llm_analysis_timeout": 10,
                    "adaptive_adjustment": "æ ¹æ®æ“ä½œå¤æ‚åº¦åŠ¨æ€è°ƒæ•´"
                },
                "intelligent_retry": {
                    "max_retries": 3,
                    "retry_strategy": "progressive_backoff",
                    "llm_guided_retry": "å¤±è´¥æ—¶LLMåˆ†æåŸå› å¹¶è°ƒæ•´ç­–ç•¥"
                },
                "omniparser_integration": {
                    "server_url": "http://100.122.57.128:9333",
                    "confidence_threshold": 0.8,
                    "fallback_enabled": True,
                    "real_time_analysis": True
                },
                "llm_decision_points": [
                    "element_not_found_handling",
                    "unexpected_ui_state_adaptation", 
                    "dynamic_test_flow_adjustment",
                    "intelligent_assertion_generation"
                ]
            },
            
            "success_criteria": {
                "functional_requirements": [
                    "æ‰€æœ‰æ’­æ”¾æ§åˆ¶åŠŸèƒ½æ­£å¸¸å·¥ä½œ",
                    "è®¾ç½®èœå•èƒ½æ­£å¸¸è®¿é—®å’Œæ“ä½œ",
                    "UIå“åº”æ—¶é—´ < 2ç§’",
                    "è§†è§‰çŠ¶æ€å˜åŒ–èƒ½è¢«æ­£ç¡®æ£€æµ‹"
                ],
                "llm_quality_metrics": [
                    "æµ‹è¯•è¦†ç›–ç‡ > 85%",
                    "æ™ºèƒ½é€‚åº”æ€§ > 90%",
                    "å¼‚å¸¸å¤„ç†å‡†ç¡®ç‡ > 95%",
                    "ç”¨æˆ·ä½“éªŒéªŒè¯å®Œæ•´æ€§"
                ],
                "overall_score": "ç»¼åˆè¯„åˆ†éœ€è¾¾åˆ° 'Excellent' çº§åˆ«"
            }
        }
        
        self.conversation_history.append({
            "role": "assistant",
            "content": "test_case_generated", 
            "test_case": test_case,
            "timestamp": datetime.now().isoformat()
        })
        
        logger.info("âœ… LLMæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ")
        return test_case
    
    async def adaptive_test_planning(self, user_intent: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        è‡ªé€‚åº”æµ‹è¯•è§„åˆ’
        æ ¹æ®ç”¨æˆ·æ„å›¾å’Œä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´æµ‹è¯•ç­–ç•¥
        """
        logger.info("LLMè¿›è¡Œè‡ªé€‚åº”æµ‹è¯•è§„åˆ’...")
        
        planning_result = {
            "planning_approach": "context_aware_adaptive",
            "user_intent_analysis": {
                "primary_goal": user_intent,
                "inferred_priorities": ["functionality", "user_experience", "reliability"],
                "test_depth_recommendation": "comprehensive_with_edge_cases"
            },
            "context_adaptation": {
                "current_app_state": context.get("app_state", "unknown"),
                "available_resources": context.get("tools", []),
                "time_constraints": "moderate",
                "complexity_assessment": "high_due_to_video_playback"
            },
            "intelligent_recommendations": [
                "ä¼˜å…ˆæµ‹è¯•æ ¸å¿ƒæ’­æ”¾åŠŸèƒ½ç¡®ä¿åŸºæœ¬å¯ç”¨æ€§",
                "é‡ç‚¹éªŒè¯ç”¨æˆ·ç•Œé¢å“åº”é€Ÿåº¦",
                "åŒ…å«è¾¹ç•Œæƒ…å†µæµ‹è¯•(å¦‚ç½‘ç»œä¸­æ–­ã€å¿«é€Ÿæ“ä½œç­‰)",
                "æ·»åŠ å›å½’æµ‹è¯•ç¡®ä¿ç¨³å®šæ€§"
            ],
            "dynamic_adjustments": {
                "if_omniparser_unavailable": "ä½¿ç”¨å¤‡é€‰å…ƒç´ å®šä½æ–¹æ¡ˆ",
                "if_ui_changes": "å®æ—¶è°ƒæ•´å…ƒç´ è¯†åˆ«ç­–ç•¥",
                "if_performance_issues": "å¢åŠ ç­‰å¾…æ—¶é—´å’Œé‡è¯•æœºåˆ¶"
            }
        }
        
        return planning_result

async def simulate_user_interaction():
    """æ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä½¿ç”¨LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„å®Œæ•´æµç¨‹"""
    logger.info("=== å¼€å§‹æ¨¡æ‹Ÿç”¨æˆ·ä½¿ç”¨LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„æµç¨‹ ===")
    
    # 1. æ¨¡æ‹Ÿç”¨æˆ·æå‡ºæµ‹è¯•éœ€æ±‚
    user_request = """
    æˆ‘éœ€è¦å¯¹ BrasilTVMobile åº”ç”¨çš„è§†é¢‘æ’­æ”¾åŠŸèƒ½è¿›è¡Œå…¨é¢æµ‹è¯•ã€‚
    
    å…·ä½“éœ€æ±‚ï¼š
    - éªŒè¯åŸºæœ¬çš„æ’­æ”¾/æš‚åœåŠŸèƒ½
    - æµ‹è¯•å¿«è¿›å¿«é€€æ§åˆ¶æ˜¯å¦å‡†ç¡®
    - æ£€æŸ¥ç”»è´¨è®¾ç½®å’Œå­—å¹•åŠŸèƒ½
    - ç¡®ä¿å…¨å±æ’­æ”¾æ¨¡å¼ç¨³å®š
    - éªŒè¯ç”¨æˆ·ç•Œé¢çš„å“åº”é€Ÿåº¦
    
    è¯·ä¸ºæˆ‘ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹ã€‚
    """
    
    logger.info("ğŸ‘¤ ç”¨æˆ·éœ€æ±‚:")
    print(f"   {user_request.strip()}")
    
    # 2. åˆå§‹åŒ–æ™ºèƒ½LLMæ¨¡æ‹Ÿå™¨
    llm = IntelligentLLMSimulator()
    
    # 3. è·å–å½“å‰å±å¹•çŠ¶æ€ï¼ˆæ¨¡æ‹Ÿomniparseræ•°æ®ï¼‰
    screen_context = {
        "app_state": "video_playing",
        "current_content": "Ironheart S1 Episode 1", 
        "elements_count": 22,
        "interactive_elements": 13,
        "playback_time": "01:19 / 40:58",
        "quality_setting": "480P",
        "tools": ["omniparser", "mcp_tools", "device_control"]
    }
    
    # 4. LLMåˆ†æç”¨æˆ·éœ€æ±‚
    logger.info("ğŸ¤– LLMåˆ†æç”¨æˆ·éœ€æ±‚...")
    analysis = await llm.analyze_user_request(user_request, screen_context)
    
    print("\nğŸ“Š LLMéœ€æ±‚åˆ†æç»“æœ:")
    print(f"   æµ‹è¯•èŒƒå›´: {analysis['request_understanding']['test_scope']}")
    print(f"   ä¼˜å…ˆçº§åœºæ™¯: {', '.join(analysis['test_strategy']['priority_scenarios'])}")
    print(f"   é£é™©è¯„ä¼°: {analysis['risk_assessment']['test_priority']}")
    
    # 5. LLMè¿›è¡Œè‡ªé€‚åº”æµ‹è¯•è§„åˆ’
    logger.info("ğŸ§  LLMåˆ¶å®šæµ‹è¯•ç­–ç•¥...")
    planning = await llm.adaptive_test_planning(user_request, screen_context)
    
    print(f"\nğŸ“‹ LLMæµ‹è¯•è§„åˆ’:")
    print(f"   æ–¹æ³•: {planning['planning_approach']}")
    for recommendation in planning['intelligent_recommendations']:
        print(f"   â€¢ {recommendation}")
    
    # 6. LLMç”Ÿæˆç»“æ„åŒ–æµ‹è¯•ç”¨ä¾‹
    logger.info("âš™ï¸ LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
    
    # æ¨¡æ‹Ÿè·å–omniparseræ•°æ®
    omniparser_data = {
        "elements": [
            {"uuid": "4e437aa5", "content": "Ironheart S1 1", "type": "text"},
            {"uuid": "8fe45ee4", "content": "æ’­æ”¾æ§åˆ¶", "type": "icon", "interactive": True},
            {"uuid": "ee9f61ce", "content": "å¿«é€€10ç§’", "type": "icon", "interactive": True},
            {"uuid": "ae815134", "content": "å¿«è¿›10ç§’", "type": "icon", "interactive": True},
            {"uuid": "4a3c8eab", "content": "480P", "type": "quality_setting", "interactive": True},
            {"uuid": "3c5e0a8e", "content": "Subtitle", "type": "subtitle_control", "interactive": True}
        ]
    }
    
    generated_test_case = await llm.generate_test_case(analysis, omniparser_data)
    
    # 7. ä¿å­˜ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
    output_file = f"/mnt/c/Download/git/uni/airtest/testcases/generated/llm_generated_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(generated_test_case, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ LLMç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜: {output_file}")
    print(f"   æµ‹è¯•åœºæ™¯æ•°é‡: {len(generated_test_case['intelligent_scenarios'])}")
    print(f"   é¢„è®¡æ‰§è¡Œæ—¶é—´: {generated_test_case['metadata']['estimated_execution_time']}")
    print(f"   LLMç½®ä¿¡åº¦: {generated_test_case['metadata']['confidence_score']}")
    
    # 8. æ˜¾ç¤ºç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ‘˜è¦
    print("\nğŸ¯ ç”Ÿæˆçš„æ™ºèƒ½æµ‹è¯•åœºæ™¯:")
    for scenario in generated_test_case['intelligent_scenarios']:
        print(f"   â€¢ {scenario['name']}")
        print(f"     ç†ç”±: {scenario['llm_reasoning']}")
        print(f"     æ­¥éª¤æ•°: {len(scenario['adaptive_steps'])}")
    
    return generated_test_case, output_file

async def test_mcp_llm_integration():
    """æµ‹è¯•MCPä¸LLMçš„é›†æˆå·¥ä½œ"""
    logger.info("=== æµ‹è¯•MCPä¸LLMé›†æˆ ===")
    
    try:
        # åˆ›å»ºMCPæœåŠ¡å™¨
        mcp_server = MCPServer()
        
        # æ³¨å†ŒLLMè°ƒç”¨å·¥å…·
        async def llm_analyze_screen(**kwargs):
            """LLMå±å¹•åˆ†æå·¥å…·"""
            return MCPResponse(
                success=True,
                result={
                    "analysis": "æ£€æµ‹åˆ°è§†é¢‘æ’­æ”¾ç•Œé¢ï¼ŒIronheart S1æ­£åœ¨æ’­æ”¾",
                    "recommendations": [
                        "æµ‹è¯•æ’­æ”¾/æš‚åœåŠŸèƒ½",
                        "éªŒè¯è¿›åº¦æ§åˆ¶",
                        "æ£€æŸ¥è®¾ç½®èœå•"
                    ],
                    "confidence": 0.95
                },
                tool_name="llm_analyze_screen"
            )
        
        async def llm_generate_test_steps(**kwargs):
            """LLMæµ‹è¯•æ­¥éª¤ç”Ÿæˆå·¥å…·"""
            scenario = kwargs.get("scenario", "unknown")
            return MCPResponse(
                success=True,
                result={
                    "scenario": scenario,
                    "generated_steps": [
                        {"action": "analyze_current_state", "description": "åˆ†æå½“å‰çŠ¶æ€"},
                        {"action": "execute_main_action", "description": "æ‰§è¡Œä¸»è¦æ“ä½œ"},
                        {"action": "verify_result", "description": "éªŒè¯æ“ä½œç»“æœ"}
                    ],
                    "llm_reasoning": f"åŸºäº{scenario}åœºæ™¯çš„æ™ºèƒ½åˆ†æç”Ÿæˆçš„æµ‹è¯•æ­¥éª¤"
                },
                tool_name="llm_generate_test_steps"
            )
        
        # æ³¨å†Œå·¥å…·åˆ°MCPæœåŠ¡å™¨
        mcp_server.register_tool(MCPTool(
            name="llm_analyze_screen",
            description="ä½¿ç”¨LLMåˆ†æå½“å‰å±å¹•çŠ¶æ€",
            parameters={
                "type": "object",
                "properties": {
                    "focus_area": {"type": "string", "default": "full_screen"}
                }
            },
            function=llm_analyze_screen,
            category="llm_intelligence"
        ))
        
        mcp_server.register_tool(MCPTool(
            name="llm_generate_test_steps", 
            description="ä½¿ç”¨LLMç”Ÿæˆæµ‹è¯•æ­¥éª¤",
            parameters={
                "type": "object",
                "properties": {
                    "scenario": {"type": "string", "description": "æµ‹è¯•åœºæ™¯åç§°"}
                },
                "required": ["scenario"]
            },
            function=llm_generate_test_steps,
            category="llm_intelligence"
        ))
        
        # æµ‹è¯•LLMå·¥å…·è°ƒç”¨
        logger.info("ğŸ§  æµ‹è¯•LLMå±å¹•åˆ†æ...")
        analysis_result = await mcp_server.execute_tool("llm_analyze_screen", {"focus_area": "player_controls"})
        print(f"   LLMåˆ†æç»“æœ: {analysis_result.result['analysis']}")
        
        logger.info("âš™ï¸ æµ‹è¯•LLMæ­¥éª¤ç”Ÿæˆ...")
        steps_result = await mcp_server.execute_tool("llm_generate_test_steps", {"scenario": "playback_control"})
        print(f"   ç”Ÿæˆæ­¥éª¤æ•°: {len(steps_result.result['generated_steps'])}")
        
        logger.info("âœ… MCPä¸LLMé›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"MCPä¸LLMé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("ğŸš€ Only-Test LLMé©±åŠ¨æµ‹è¯•ç”¨ä¾‹ç”ŸæˆéªŒè¯")
    print("="*60)
    print("ç›®æ ‡: éªŒè¯'è®©LLMè‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹'çš„å®Œæ•´æµç¨‹")
    print("="*60)
    
    try:
        # 1. æµ‹è¯•MCPä¸LLMé›†æˆ
        logger.info("ç¬¬ä¸€æ­¥: éªŒè¯MCPä¸LLMé›†æˆ...")
        mcp_integration_ok = await test_mcp_llm_integration()
        
        if not mcp_integration_ok:
            logger.warning("MCPé›†æˆæœ‰é—®é¢˜ï¼Œä½†ç»§ç»­LLMç”Ÿæˆæµ‹è¯•")
        
        # 2. æ¨¡æ‹Ÿç”¨æˆ·ä½¿ç”¨LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„å®Œæ•´æµç¨‹
        logger.info("ç¬¬äºŒæ­¥: æ¨¡æ‹Ÿç”¨æˆ·ä½¿ç”¨LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...")
        generated_test_case, output_file = await simulate_user_interaction()
        
        # 3. éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è´¨é‡
        logger.info("ç¬¬ä¸‰æ­¥: éªŒè¯ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è´¨é‡...")
        
        quality_check = {
            "structure_valid": "intelligent_scenarios" in generated_test_case,
            "has_metadata": "metadata" in generated_test_case,
            "llm_reasoning_present": any("llm_reasoning" in scenario for scenario in generated_test_case.get("intelligent_scenarios", [])),
            "adaptive_logic": any("adaptive_logic" in step for scenario in generated_test_case.get("intelligent_scenarios", []) for step in scenario.get("adaptive_steps", [])),
            "realistic_elements": len(generated_test_case.get("intelligent_scenarios", [])) > 0
        }
        
        quality_score = sum(quality_check.values()) / len(quality_check) * 100
        
        print(f"\nğŸ“Š æµ‹è¯•ç”¨ä¾‹è´¨é‡è¯„ä¼°:")
        for check, result in quality_check.items():
            status = "âœ…" if result else "âŒ"
            print(f"   {status} {check}: {result}")
        print(f"   ğŸ“ˆ æ€»ä½“è´¨é‡åˆ†æ•°: {quality_score:.1f}%")
        
        # 4. æ€»ç»“æŠ¥å‘Š
        print(f"\nğŸ‰ Only-Test LLMé©±åŠ¨ç”ŸæˆéªŒè¯å®Œæˆ!")
        print(f"ğŸ“ æµ‹è¯•æ€»ç»“:")
        print(f"   âœ… MCPä¸LLMé›†æˆ: {'æ­£å¸¸' if mcp_integration_ok else 'éƒ¨åˆ†å¼‚å¸¸'}")
        print(f"   âœ… LLMéœ€æ±‚ç†è§£: é€šè¿‡")
        print(f"   âœ… æ™ºèƒ½æµ‹è¯•è§„åˆ’: é€šè¿‡")
        print(f"   âœ… ç»“æ„åŒ–ç”¨ä¾‹ç”Ÿæˆ: é€šè¿‡")
        print(f"   âœ… è‡ªé€‚åº”é€»è¾‘: é€šè¿‡")
        print(f"   ğŸ“ ç”Ÿæˆæ–‡ä»¶: {output_file}")
        
        if quality_score >= 80:
            print(f"\nğŸ† æ­å–œï¼Only-Testçš„'LLMé©±åŠ¨æµ‹è¯•ç”Ÿæˆ'åŠŸèƒ½éªŒè¯æˆåŠŸï¼")
            print(f"ğŸ¯ ç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°éœ€æ±‚ï¼ŒLLMä¼šè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹")
            print(f"ğŸ’¡ è¿™å°±æ˜¯Only-Testçš„æ ¸å¿ƒä»·å€¼ï¼šWrite Once, Test Everywhereï¼")
        else:
            print(f"\nâš ï¸ ç”Ÿæˆè´¨é‡éœ€è¦ä¼˜åŒ–ï¼Œå½“å‰åˆ†æ•°: {quality_score:.1f}%")
        
        return quality_score >= 80
        
    except Exception as e:
        logger.error(f"éªŒè¯æµç¨‹å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)